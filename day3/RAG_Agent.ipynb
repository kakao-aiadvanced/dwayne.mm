{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T08:46:01.708391Z",
     "start_time": "2025-03-26T08:45:55.775046Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain_community langchainhub chromadb langchain langgraph tavily-python langchain-text-splitters langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import getpass\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from tavily import TavilyClient\n",
    "tavily_key = getpass.getpass()\n",
    "tavily = TavilyClient(api_key=tavily_key)\n",
    "\n",
    "### Index\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19ce41d200a50e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T08:46:01.712966Z",
     "start_time": "2025-03-26T08:46:01.711167Z"
    }
   },
   "outputs": [],
   "source": [
    "### Router\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "Use the vectorstore for questions on LLM agents, prompt engineering, and adversarial attacks.\n",
    "You do not need to be stringent with the keywords in the question related to these topics.\n",
    "Otherwise, use web-search. Give a binary choice 'web_search' or 'vectorstore' based on the question.\n",
    "Return the a JSON with a single key 'datasource' and no premable or explanation. Question to route\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# question = \"llm agent memory\"\n",
    "# question = \"What is prompt?\"\n",
    "# docs = retriever.get_relevant_documents(question)\n",
    "# print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24f3efa2070283e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T08:46:01.779043Z",
     "start_time": "2025-03-26T08:46:01.777352Z"
    }
   },
   "outputs": [],
   "source": [
    "### Retrieval Grader\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are a grader assessing relevance\n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question,\n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "    \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"question: {question}\\n\\n document: {document} \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "# question = \"What is prompt?\"\n",
    "# docs = retriever.invoke(question)\n",
    "# doc_txt = docs[0].page_content\n",
    "# print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659402a27c9c1693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T08:46:01.785705Z",
     "start_time": "2025-03-26T08:46:01.784166Z"
    }
   },
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"question: {question}\\n\\n context: {context} \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "# question = \"What is prompt?\"\n",
    "# docs = retriever.invoke(question)\n",
    "# generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "# print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3da3221c025f88e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T08:46:01.792423Z",
     "start_time": "2025-03-26T08:46:01.790900Z"
    }
   },
   "outputs": [],
   "source": [
    "### Hallucination Grader\n",
    "system = \"\"\"You are a grader assessing whether\n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate\n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a\n",
    "    single key 'score' and no preamble or explanation.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"documents: {documents}\\n\\n answer: {generation} \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "#hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a0a83cf7932da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T08:46:01.799137Z",
     "start_time": "2025-03-26T08:46:01.797589Z"
    }
   },
   "outputs": [],
   "source": [
    "### Answer Grader\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an\n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is\n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"question: {question}\\n\\n answer: {generation} \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "#answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c665ed08dc4fc64f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T08:53:19.927805Z",
     "start_time": "2025-03-26T08:53:12.473649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- start ----\n",
      "\n",
      "--- docs_retrieval ----\n",
      "\n",
      "--- relevance_checker ----\n",
      "\n",
      "--- generate_answer ----\n",
      "\n",
      "--- hallucination_checker ----\n",
      "\n",
      "--- answer_to_user ----\n",
      "\n",
      "\n",
      "최종 답변:\n",
      "Prompt engineering, also known as in-context prompting, involves methods to communicate with large language models (LLMs) to guide their behavior towards desired outcomes without altering the model's weights. It is an empirical science that requires experimentation, as the effectiveness of these methods can vary significantly across different models. The primary goal is to achieve alignment and steerability of the model.\n",
      "\n",
      "참조한 문서:\n",
      "- Vectorstore 검색 결과:\n",
      "  내용: Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
      "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\n",
      "[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\n",
      "Basic Prompting#\n",
      "- Vectorstore 검색 결과:\n",
      "  내용: Or\n",
      "@article{weng2023prompt,\n",
      "  title   = \"Prompt Engineering\",\n",
      "  author  = \"Weng, Lilian\",\n",
      "  journal = \"lilianweng.github.io\",\n",
      "  year    = \"2023\",\n",
      "  month   = \"Mar\",\n",
      "  url     = \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\n",
      "}\n",
      "Useful Resources#\n",
      "\n",
      "OpenAI Cookbook has many in-depth examples for how to utilize LLM efficiently.\n",
      "LangChain, a library for combining language models with other components to build applications.\n",
      "Prompt Engineering Guide repo contains a pretty comprehensive collection of education materials on prompt engineering.\n",
      "learnprompting.org\n",
      "PromptPerfect\n",
      "Semantic Kernel\n",
      "- Vectorstore 검색 결과:\n",
      "  내용: Prompt Engineering | Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Prompt Engineering\n",
      "    \n",
      "Date: March 15, 2023  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "Basic Prompting\n",
      "\n",
      "Zero-Shot\n",
      "\n",
      "Few-shot\n",
      "\n",
      "Tips for Example Selection\n",
      "\n",
      "Tips for Example Ordering\n",
      "\n",
      "\n",
      "\n",
      "Instruction Prompting\n",
      "\n",
      "Self-Consistency Sampling\n",
      "\n",
      "Chain-of-Thought (CoT)\n",
      "\n",
      "Types of CoT prompts\n",
      "\n",
      "Tips and Extensions\n",
      "\n",
      "\n",
      "Automatic Prompt Design\n",
      "\n",
      "Augmented Language Models\n",
      "\n",
      "Retrieval\n",
      "\n",
      "Programming Language\n",
      "\n",
      "External APIs\n",
      "\n",
      "\n",
      "Citation\n",
      "\n",
      "Useful Resources\n",
      "\n",
      "References\n",
      "- Vectorstore 검색 결과:\n",
      "  내용: At inference time, decoding runs until the model produces “$\\to$ \" token, indicating that it is expecting response from an API call next.\n",
      "Toolformer currently does not support tool use in a chain (i.e. using the output of one tool as an input for another tool) or in an interactive way (i.e. adopt API response after human selection). Both are interesting future directions to expand the model for.\n",
      "Citation#\n",
      "Cited as:\n",
      "\n",
      "Weng, Lilian. (Mar 2023). Prompt Engineering. Lil’Log. https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    need_websearch: bool\n",
    "    documents: List[str]\n",
    "    hallucination_try: bool\n",
    "    websearch_try_cnt: int\n",
    "    hallucination_result: bool\n",
    "\n",
    "def start(state):\n",
    "    print(\"--- start ----\\n\")\n",
    "    return {\"question\": state[\"question\"],\n",
    "            \"generation\": \"\",\n",
    "            \"need_websearch\": False,\n",
    "            \"documents\": [],\n",
    "            \"hallucination_try\": False,\n",
    "            \"websearch_try_cnt\": 0,\n",
    "            \"hallucination_result\": False}\n",
    "\n",
    "def docs_retrieval(state):\n",
    "    print(\"--- docs_retrieval ----\\n\")\n",
    "    docs = retriever.invoke(state[\"question\"])\n",
    "    # 메타데이터 추가\n",
    "    for doc in docs:\n",
    "        doc.metadata[\"source\"] = \"vectorstore\"\n",
    "    state[\"documents\"] = docs\n",
    "    return {\"question\": state[\"question\"],\n",
    "            \"generation\": state[\"generation\"],\n",
    "            \"need_websearch\": state[\"need_websearch\"],\n",
    "            \"documents\": state[\"documents\"],\n",
    "            \"hallucination_try\": state[\"hallucination_try\"],\n",
    "            \"websearch_try_cnt\": state[\"websearch_try_cnt\"],\n",
    "            \"hallucination_result\": state[\"hallucination_result\"]}\n",
    "\n",
    "\n",
    "def relevance_checker(state):\n",
    "    print(\"--- relevance_checker ----\\n\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    state[\"documents\"] = []\n",
    "    state[\"need_websearch\"] = False\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        if grade.lower() == \"yes\":\n",
    "            state[\"documents\"].append(d)\n",
    "        else:\n",
    "            state[\"need_websearch\"] = True\n",
    "            continue\n",
    "\n",
    "    if state[\"websearch_try_cnt\"] >= 1 and state[\"need_websearch\"]:\n",
    "        print(\"\\n\\nwebsearch를 2회 했지만 relevance에 실패 했습니다. 종료합니다.\")\n",
    "        return END\n",
    "\n",
    "    return {\"question\": state[\"question\"],\n",
    "            \"generation\": state[\"generation\"],\n",
    "            \"need_websearch\": state[\"need_websearch\"],\n",
    "            \"documents\": state[\"documents\"],\n",
    "            \"hallucination_try\": state[\"hallucination_try\"],\n",
    "            \"websearch_try_cnt\": state[\"websearch_try_cnt\"],\n",
    "            \"hallucination_result\": state[\"hallucination_result\"]}\n",
    "\n",
    "def websearch_tavaily(state):\n",
    "    print(\"--- websearch_tavaily ----\\n\")\n",
    "    question = state[\"question\"]\n",
    "    documents = None\n",
    "    if \"documents\" in state:\n",
    "        documents = state[\"documents\"]\n",
    "\n",
    "    docs = tavily.search(query=question)['results']\n",
    "    web_results = []\n",
    "    for d in docs:\n",
    "        doc = Document(\n",
    "            page_content=d[\"content\"],\n",
    "            metadata={\"url\": d[\"url\"]}\n",
    "        )\n",
    "        web_results.append(doc)\n",
    "\n",
    "    if documents is not None:\n",
    "        documents.extend(web_results)\n",
    "    else:\n",
    "        documents = web_results\n",
    "\n",
    "    return {\"question\": state[\"question\"],\n",
    "            \"generation\": state[\"generation\"],\n",
    "            \"need_websearch\": state[\"need_websearch\"],\n",
    "            \"documents\": documents,\n",
    "            \"hallucination_try\": state[\"hallucination_try\"],\n",
    "            \"websearch_try_cnt\": state[\"websearch_try_cnt\"] + 1,\n",
    "            \"hallucination_result\": state[\"hallucination_result\"]}\n",
    "\n",
    "def generate_answer(state):\n",
    "    print(\"--- generate_answer ----\\n\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    state[\"generation\"] = generation\n",
    "\n",
    "    return {\"question\": state[\"question\"],\n",
    "            \"generation\": state[\"generation\"],\n",
    "            \"need_websearch\": state[\"need_websearch\"],\n",
    "            \"documents\": state[\"documents\"],\n",
    "            \"hallucination_try\": state[\"hallucination_try\"],\n",
    "            \"websearch_try_cnt\": state[\"websearch_try_cnt\"],\n",
    "            \"hallucination_result\": state[\"hallucination_result\"]}\n",
    "\n",
    "def hallucination_checker(state):\n",
    "    print(\"--- hallucination_checker ----\\n\")\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score[\"score\"]\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        state[\"hallucination_result\"] = False\n",
    "    else:\n",
    "        state[\"hallucination_result\"] = True\n",
    "\n",
    "    if state[\"hallucination_try\"] == True and state[\"hallucination_result\"] == True:\n",
    "        print(\"failed: hallucinated\")\n",
    "        return END\n",
    "\n",
    "    return {\"question\": state[\"question\"],\n",
    "            \"generation\": state[\"generation\"],\n",
    "            \"need_websearch\": state[\"need_websearch\"],\n",
    "            \"documents\": state[\"documents\"],\n",
    "            \"hallucination_try\": state[\"hallucination_try\"],\n",
    "            \"websearch_try_cnt\": state[\"websearch_try_cnt\"],\n",
    "            \"hallucination_result\": state[\"hallucination_result\"]}\n",
    "\n",
    "def answer_to_user(state):\n",
    "    print(\"--- answer_to_user ----\\n\")\n",
    "    return {\"question\": state[\"question\"],\n",
    "            \"generation\": state[\"generation\"],\n",
    "            \"need_websearch\": state[\"need_websearch\"],\n",
    "            \"documents\": state[\"documents\"],\n",
    "            \"hallucination_try\": state[\"hallucination_try\"],\n",
    "            \"websearch_try_cnt\": state[\"websearch_try_cnt\"],\n",
    "            \"hallucination_result\": state[\"hallucination_result\"]}\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"start\", start)\n",
    "workflow.add_node(\"docs_retrieval\", docs_retrieval)\n",
    "workflow.add_node(\"relevance_checker\", relevance_checker)\n",
    "workflow.add_node(\"websearch_tavaily\", websearch_tavaily)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_node(\"hallucination_checker\", hallucination_checker)\n",
    "workflow.add_node(\"answer_to_user\", answer_to_user)\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"start\")\n",
    "workflow.add_edge(\"start\", \"docs_retrieval\")\n",
    "workflow.add_edge(\"docs_retrieval\", \"relevance_checker\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_checker\",\n",
    "    lambda result: result[\"need_websearch\"],\n",
    "    {\n",
    "        False: \"generate_answer\",\n",
    "        True: \"websearch_tavaily\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"websearch_tavaily\", \"relevance_checker\")\n",
    "workflow.add_edge(\"generate_answer\", \"hallucination_checker\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"hallucination_checker\",\n",
    "    lambda result: result[\"hallucination_result\"],\n",
    "    {\n",
    "        False: \"answer_to_user\",\n",
    "        True: \"generate_answer\"\n",
    "     },\n",
    ")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "#inputs = {\"question\": \"메시는 현재 어느팀에서 뛰나요?\"}\n",
    "inputs = {\"question\": \"What is promopt-engineering?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        if key == \"answer_to_user\":\n",
    "            print(\"\\n최종 답변:\")\n",
    "            print(value[\"generation\"])\n",
    "            print(\"\\n참조한 문서:\")\n",
    "            for doc in value[\"documents\"]:\n",
    "                if \"source\" in doc.metadata:\n",
    "                    print(\"- Vectorstore 검색 결과:\")\n",
    "                    print(\"  내용:\", doc.page_content)\n",
    "                elif \"url\" in doc.metadata:\n",
    "                    print(f\"- 웹 검색 결과: {doc.metadata['url']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
