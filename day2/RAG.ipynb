{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T07:26:23.201061Z",
     "start_time": "2025-03-25T07:26:16.862971Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "import getpass\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ef87886a8b55cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T07:26:27.097140Z",
     "start_time": "2025-03-25T07:26:25.190314Z"
    }
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(urls),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "925761cb9e1fda38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T07:26:38.657534Z",
     "start_time": "2025-03-25T07:26:30.367255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP1] relevance check result: {'relevance': 'yes'}\n",
      "\n",
      "\n",
      "[STEP2] 최종 답변:\n",
      "The agent memory, as described in the context provided, refers to a long-term memory module known as the memory stream. This module records a comprehensive list of the agent's experiences in natural language, capturing each observation or event provided by the agent. \n",
      "\n",
      "Key aspects of the agent memory include:\n",
      "\n",
      "1. **Inter-agent Communication**: Communication between agents can trigger the creation of new memory entries in natural language.\n",
      "\n",
      "2. **Retrieval Model**: The memory serves to inform the agent's behavior based on three factors:\n",
      "   - **Recency**: Recent events are prioritized and have higher relevance scores.\n",
      "   - **Importance**: The memory differentiates between mundane experiences and core memories, which can be directly identified by querying the language model.\n",
      "   - **Relevance**: The memory retrieval is based on how related the stored memories are to the current situation or query posed by the agent.\n",
      "\n",
      "3. **Reflection Mechanism**: This synthesizes memories into higher-level inferences over time, guiding the agent's future actions. These inferences serve as summaries of past events and help the agent learn from previous experiences.\n",
      "\n",
      "This comprehensive memory system enhances the agent's capabilities by enabling it to learn from past actions, refine its approach to tasks, and improve problem-solving over time.\n",
      "\n",
      "\n",
      "[STEP3] 출처:\n",
      "- https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "- https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "- https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "- https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "- https://lilianweng.github.io/posts/2023-06-23-agent/\n",
      "- https://lilianweng.github.io/posts/2023-06-23-agent/\n"
     ]
    }
   ],
   "source": [
    "query = \"agent memory\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "context_text = format_docs(retrieved_docs)\n",
    "\n",
    "evaluation_template = (\n",
    "    \"retrieval 퀄리티를 LLM이 스스로 평가하도록 하세요. 문맥이 사용자 쿼리와 관련이 있으면 yes, 관련이 없으면 no로 출력합니다. relevance : yes, no 로 출력해주세요.\\n\"\n",
    "    \"{format_instructions}\\n\"\n",
    "    \"Context: {context}\\n\"\n",
    "    \"Question: {question}\\n\"\n",
    ")\n",
    "evaluation_prompt = PromptTemplate(\n",
    "    template=evaluation_template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": JsonOutputParser().get_format_instructions()},\n",
    ")\n",
    "\n",
    "evaluation_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | evaluation_prompt\n",
    "        | llm\n",
    "        | JsonOutputParser()\n",
    ")\n",
    "\n",
    "evaluation_result = evaluation_chain.invoke(query)\n",
    "print(\"[STEP1] relevance check result:\", evaluation_result)\n",
    "\n",
    "answer = \"\"\n",
    "regenerated = False\n",
    "if evaluation_result.get(\"relevance\") == \"yes\":\n",
    "    for _ in range(2):\n",
    "        answer_template = (\n",
    "            \"다음 문맥을 기반으로 사용자 질문에 답변해 주세요.\\n\"\n",
    "            \"Context: {context}\\n\"\n",
    "            \"Question: {question}\\n\"\n",
    "            \"Answer:\"\n",
    "        )\n",
    "        answer_prompt = PromptTemplate(\n",
    "            template=answer_template,\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "        rag_chain = (\n",
    "                {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                | answer_prompt\n",
    "                | llm\n",
    "                | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        for chunk in rag_chain.stream(query):\n",
    "            answer += chunk\n",
    "\n",
    "        hallucination_template = (\n",
    "            \"생성된 답안에 Hallucination(잘못된 정보나 근거 없는 내용)이 포함되어 있는지 평가하세요. 반드시 유효한 JSON 형식으로만 답변하세요. 만약 답안에 사실과 다르거나 허위 내용이 있다면 yes, 허위 내용이 없다면 no로 출력합니다. hallucination : yes, no 로 출력해주세요.\\n\"\n",
    "            \"{format_instructions}\\n\"\n",
    "            \"Context: {context}\\n\"\n",
    "            \"Answer: {answer}\\n\"\n",
    "        )\n",
    "        hallucination_prompt = PromptTemplate(\n",
    "            template=hallucination_template,\n",
    "            input_variables=[\"context\", \"answer\"],\n",
    "            partial_variables={\"format_instructions\": JsonOutputParser().get_format_instructions()},\n",
    "        )\n",
    "        hallucination_chain = hallucination_prompt | llm | JsonOutputParser()\n",
    "        hallucination_result = hallucination_chain.invoke({\"context\": context_text, \"answer\": answer})\n",
    "\n",
    "        #hallucination_result['hallucination'] = \"yes\" (할루시네이션 테스트)\n",
    "\n",
    "        if hallucination_result.get(\"hallucination\") == \"no\":\n",
    "            break\n",
    "        elif hallucination_result.get(\"hallucination\") == \"yes\":\n",
    "            if regenerated:\n",
    "                print(\"\\n최대 재생성 횟수(1회)를 초과\\n\")\n",
    "                answer = \"\"\n",
    "                break\n",
    "            else:\n",
    "                print(\"\\nhallucination 감지됨: 답변을 다시 생성합니다.\\n\")\n",
    "                regenerated = True\n",
    "else:\n",
    "    print(\"\\nRetrieved chunks are not relevant to the query.\")\n",
    "\n",
    "####### RESULT ######\n",
    "if answer != \"\":\n",
    "    print(\"\\n\\n[STEP2] 최종 답변:\")\n",
    "    print(answer)\n",
    "    print(\"\\n\\n[STEP3] 출처:\")\n",
    "    for doc in retrieved_docs:\n",
    "        source = doc.metadata.get(\"source\", \"출처 정보 없음\") if hasattr(doc, \"metadata\") else \"출처 정보 없음\"\n",
    "        print(\"-\", source)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
